\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{KouwL21}
\citation{Azizzadenesheli19}
\citation{Combes0WG20}
\citation{SinghalWRK23}
\citation{HuangSGBS06}
\citation{SunCPY11}
\citation{DaumeIII07}
\citation{DaumeKS10}
\citation{DuanXT12}
\citation{BaktashmotlaghHLS13}
\citation{PanTKY11}
\citation{YaoPNLM15}
\citation{SinghalWRK23}
\citation{WangD18}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\citation{ZengSRGFZ25}
\citation{WangYXWZW23}
\citation{DXiaLZSL25}
\citation{YangZLLLC25}
\citation{GaninUAGLLML16}
\citation{TzengHSD17}
\citation{TangJ20}
\citation{ZonooziS23}
\citation{GhifaryKZBL16}
\citation{BousmalisTSKE16}
\citation{ZonooziSD25}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{LongCWJ15}
\citation{SunS16}
\citation{CourtyFTR17}
\citation{DamodaranKFTC18}
\citation{HamriBF25}
\citation{SinghalWRK23}
\citation{ZonooziS23}
\citation{RedkoMHS20}
\citation{BenDavidBCP06}
\citation{MansourMR09}
\citation{ZhangLLJ19}
\citation{DhouibRL20}
\citation{WangM24}
\citation{ZhouTPT19}
\citation{FangLLZ23}
\citation{WangS15}
\citation{ZhouTPT19}
\citation{WangS15}
\citation{TomerWH16}
\citation{McNamaraB17}
\citation{JiaoLLY24}
\citation{AnthonyB02}
\citation{NeyshaburTS15}
\citation{WeiM19}
\citation{VardiSS22}
\citation{DanielyG24}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\citation{GaninUAGLLML16}
\citation{TzengHSD17}
\citation{TangJ20}
\citation{Vural18}
\newlabel{sec:gen_bounds}{{2}{4}{General performance bounds for domain alignment}{section.2}{}}
\newlabel{sec:gen_bounds@cref}{{[section][2][]2}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}General performance bounds for domain alignment}{4}{section.2}\protected@file@percent }
\newlabel{ssec:problem_form}{{2.1}{4}{Problem formulation}{subsection.3}{}}
\newlabel{ssec:problem_form@cref}{{[subsection][1][2]2.1}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem formulation}{4}{subsection.3}\protected@file@percent }
\newlabel{eq:obj_learning}{{2.1}{4}{Problem formulation}{equation.4}{}}
\newlabel{eq:obj_learning@cref}{{[equation][1][2]2.1}{[1][4][]4}}
\newlabel{eq_emp_cl_loss}{{2.2}{4}{Problem formulation}{equation.5}{}}
\newlabel{eq_emp_cl_loss@cref}{{[equation][2][2]2.2}{[1][4][]4}}
\newlabel{fig:illus_domain_relation_a}{{1a}{5}{Subfigure 1a}{subfigure.8}{}}
\newlabel{fig:illus_domain_relation_a@cref}{{[subfigure][1][1]1a}{[1][4][]5}}
\newlabel{sub@fig:illus_domain_relation_a}{{(a)}{a}{Subfigure 1a\relax }{subfigure.8}{}}
\newlabel{fig:illus_domain_relation_b}{{1b}{5}{Subfigure 1b}{subfigure.9}{}}
\newlabel{fig:illus_domain_relation_b@cref}{{[subfigure][2][1]1b}{[1][4][]5}}
\newlabel{sub@fig:illus_domain_relation_b}{{(b)}{b}{Subfigure 1b\relax }{subfigure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of \cref  {assum_existence_LLs}. Red and blue colors represent two different classes in the source and target domains $\ensuremath  {\mathcal  {X}^s}$ and $\ensuremath  {\mathcal  {X}^t}$. In (a), the two domains are well-aligned by the learnt transformations; therefore, the source and target losses are similar. In (b), the learnt transformations do not align the domains well; therefore, the difference between the source and target losses can be high.}}{5}{figure.7}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{5}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{5}{subfigure.1.2}\protected@file@percent }
\newlabel{fig:illus_domain_relation}{{1}{5}{Illustration of \cref {assum_existence_LLs}. Red and blue colors represent two different classes in the source and target domains $\Xs $ and $\Xt $. In (a), the two domains are well-aligned by the learnt transformations; therefore, the source and target losses are similar. In (b), the learnt transformations do not align the domains well; therefore, the difference between the source and target losses can be high}{figure.7}{}}
\newlabel{fig:illus_domain_relation@cref}{{[figure][1][]1}{[1][4][]5}}
\newlabel{ssec:gen_bnd_arb_dist}{{2.2}{5}{Generalization bounds for arbitrary distribution distances}{subsection.6}{}}
\newlabel{ssec:gen_bnd_arb_dist@cref}{{[subsection][2][2]2.2}{[1][4][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Generalization bounds for arbitrary distribution distances}{5}{figure.7}\protected@file@percent }
\@writefile{thm}{\contentsline {assumption}{{Assumption}{2.1}{}}{5}{theorem.11}\protected@file@percent }
\newlabel{assum_existence_LLs}{{2.1}{5}{Generalization bounds for arbitrary distribution distances}{theorem.11}{}}
\newlabel{assum_existence_LLs@cref}{{[assumption][1][2]2.1}{[1][5][]5}}
\newlabel{eq:Lipsc_reg_loss}{{2.3}{5}{Generalization bounds for arbitrary distribution distances}{equation.12}{}}
\newlabel{eq:Lipsc_reg_loss@cref}{{[equation][3][2]2.3}{[1][5][]5}}
\citation{CuckerS02}
\@writefile{thm}{\contentsline {definition}{{Definition}{2.2}{}}{6}{theorem.13}\protected@file@percent }
\@writefile{thm}{\contentsline {assumption}{{Assumption}{2.3}{}}{6}{theorem.14}\protected@file@percent }
\newlabel{assum_HF_comp_Ll_Al}{{2.3}{6}{Generalization bounds for arbitrary distribution distances}{theorem.14}{}}
\newlabel{assum_HF_comp_Ll_Al@cref}{{[assumption][3][2]2.3}{[1][6][]6}}
\newlabel{eq_defn_ds_dt}{{2.4}{6}{Generalization bounds for arbitrary distribution distances}{equation.15}{}}
\newlabel{eq_defn_ds_dt@cref}{{[equation][4][2]2.4}{[1][6][]6}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{2.4}{}}{6}{theorem.16}\protected@file@percent }
\newlabel{thm:gen_defect_target}{{2.4}{6}{Generalization bounds for arbitrary distribution distances}{theorem.16}{}}
\newlabel{thm:gen_defect_target@cref}{{[theorem][4][2]2.4}{[1][6][]6}}
\newlabel{eq_prob_expr_thm1}{{2.5}{6}{Generalization bounds for arbitrary distribution distances}{equation.17}{}}
\newlabel{eq_prob_expr_thm1@cref}{{[equation][5][2]2.5}{[1][6][]6}}
\newlabel{ssec_gen_bnd_mmd}{{2.3}{7}{Generalization bounds for maximum mean discrepancy measures}{subsection.19}{}}
\newlabel{ssec_gen_bnd_mmd@cref}{{[subsection][3][2]2.3}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Generalization bounds for maximum mean discrepancy measures}{7}{subsection.19}\protected@file@percent }
\newlabel{eq:defn_D_MMD}{{2.6}{7}{Generalization bounds for maximum mean discrepancy measures}{equation.20}{}}
\newlabel{eq:defn_D_MMD@cref}{{[equation][6][2]2.6}{[1][7][]7}}
\newlabel{eq:defn_hD_MMD}{{2.7}{7}{Generalization bounds for maximum mean discrepancy measures}{equation.22}{}}
\newlabel{eq:defn_hD_MMD@cref}{{[equation][7][2]2.7}{[1][7][]7}}
\citation{Yurinski76}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{2.5}{}}{8}{theorem.24}\protected@file@percent }
\newlabel{assum_fx_bdd_moments}{{2.5}{8}{Generalization bounds for maximum mean discrepancy measures}{theorem.24}{}}
\newlabel{assum_fx_bdd_moments@cref}{{[assumption][5][2]2.5}{[1][8][]8}}
\newlabel{eq:var_bnd_fs_ft}{{2.8}{8}{Generalization bounds for maximum mean discrepancy measures}{equation.25}{}}
\newlabel{eq:var_bnd_fs_ft@cref}{{[equation][8][2]2.8}{[1][8][]8}}
\newlabel{eq:mom_bnd_fs_ft}{{2.9}{8}{Generalization bounds for maximum mean discrepancy measures}{equation.26}{}}
\newlabel{eq:mom_bnd_fs_ft@cref}{{[equation][9][2]2.9}{[1][8][]8}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{2.6}{}}{8}{theorem.27}\protected@file@percent }
\newlabel{assum_Fs_Ft_compact}{{2.6}{8}{Generalization bounds for maximum mean discrepancy measures}{theorem.27}{}}
\newlabel{assum_Fs_Ft_compact@cref}{{[assumption][6][2]2.6}{[1][8][]8}}
\newlabel{eq_defn_dXs_dXt}{{2.10}{8}{Generalization bounds for maximum mean discrepancy measures}{equation.28}{}}
\newlabel{eq_defn_dXs_dXt@cref}{{[equation][10][2]2.10}{[1][8][]8}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{2.7}{}}{8}{theorem.29}\protected@file@percent }
\newlabel{thm:main_result_mmd}{{2.7}{8}{Generalization bounds for maximum mean discrepancy measures}{theorem.29}{}}
\newlabel{thm:main_result_mmd@cref}{{[theorem][7][2]2.7}{[1][8][]8}}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of MMD-based domain adaptation networks. Source and target samples first pass through a common network (convolutional and fully connected layers), then through domain-specific networks of $\ensuremath  {L}-1$ fully connected layers, with the $\ensuremath  {L}$-th layer being a shared classifier. The common network parameters are often adopted from pre-trained networks or fine-tuned using source samples \cite  {LongCWJ15,TzengHZSD14,GhifaryKZ14}; hence we consider feature representations at its output as our domain samples.}}{10}{figure.35}\protected@file@percent }
\newlabel{fig_illus_mmd_network}{{2}{10}{Illustration of MMD-based domain adaptation networks. Source and target samples first pass through a common network (convolutional and fully connected layers), then through domain-specific networks of $\numL -1$ fully connected layers, with the $\numL $-th layer being a shared classifier. The common network parameters are often adopted from pre-trained networks or fine-tuned using source samples \cite {LongCWJ15,TzengHZSD14,GhifaryKZ14}; hence we consider feature representations at its output as our domain samples}{figure.35}{}}
\newlabel{fig_illus_mmd_network@cref}{{[figure][2][]2}{[1][10][]10}}
\newlabel{sec_samp_dan}{{3}{10}{Sample complexity of domain-adaptive neural networks}{section.32}{}}
\newlabel{sec_samp_dan@cref}{{[section][3][]3}{[1][10][]10}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Sample complexity of domain-adaptive neural networks}{10}{section.32}\protected@file@percent }
\newlabel{ssec_samp_comp_mmd_net}{{3.1}{10}{MMD-based domain adaptation networks}{subsection.33}{}}
\newlabel{ssec_samp_comp_mmd_net@cref}{{[subsection][1][3]3.1}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}MMD-based domain adaptation networks}{10}{subsection.33}\protected@file@percent }
\newlabel{eq_defn_hsl_htl}{{3.1}{10}{MMD-based domain adaptation networks}{equation.34}{}}
\newlabel{eq_defn_hsl_htl@cref}{{[equation][1][3]3.1}{[1][10][]10}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.1}{}}{10}{theorem.37}\protected@file@percent }
\newlabel{assum_Ax_Atheta}{{3.1}{10}{MMD-based domain adaptation networks}{theorem.37}{}}
\newlabel{assum_Ax_Atheta@cref}{{[assumption][1][3]3.1}{[1][10][]10}}
\newlabel{eq_bnd_xs_xt}{{3.2}{10}{MMD-based domain adaptation networks}{equation.38}{}}
\newlabel{eq_bnd_xs_xt@cref}{{[equation][2][3]3.2}{[1][10][]10}}
\newlabel{eq_bnd_Thetaij}{{3.3}{10}{MMD-based domain adaptation networks}{equation.39}{}}
\newlabel{eq_bnd_Thetaij@cref}{{[equation][3][3]3.3}{[1][10][]10}}
\citation{LongCWJ15}
\citation{GrettonBRSS12}
\citation{GrettonBRSS12}
\citation{GrettonBRSS12}
\citation{DunfordS88}
\newlabel{eq_defn_fsl_ftl}{{3.4}{11}{MMD-based domain adaptation networks}{equation.40}{}}
\newlabel{eq_defn_fsl_ftl@cref}{{[equation][4][3]3.4}{[1][11][]11}}
\newlabel{eq_defn_inn_prod_X}{{3.5}{11}{MMD-based domain adaptation networks}{equation.41}{}}
\newlabel{eq_defn_inn_prod_X@cref}{{[equation][5][3]3.5}{[1][11][]11}}
\newlabel{eq_Fs_Ft_defn_dl}{{3.6}{11}{MMD-based domain adaptation networks}{equation.42}{}}
\newlabel{eq_Fs_Ft_defn_dl@cref}{{[equation][6][3]3.6}{[1][11][]11}}
\newlabel{eq_gs_gt_defn}{{3.7}{11}{MMD-based domain adaptation networks}{equation.43}{}}
\newlabel{eq_gs_gt_defn@cref}{{[equation][7][3]3.7}{[1][11][]11}}
\newlabel{eq_Gs_Gt_defn_dl}{{3.8}{11}{MMD-based domain adaptation networks}{equation.44}{}}
\newlabel{eq_Gs_Gt_defn_dl@cref}{{[equation][8][3]3.8}{[1][11][]11}}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\citation{WangD18}
\citation{LongCWJ15}
\citation{TzengHZSD14}
\citation{GhifaryKZ14}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.2}{}}{12}{theorem.45}\protected@file@percent }
\newlabel{assum_krl_actl_cont}{{3.2}{12}{MMD-based domain adaptation networks}{theorem.45}{}}
\newlabel{assum_krl_actl_cont@cref}{{[assumption][2][3]3.2}{[1][11][]12}}
\newlabel{eq_hD2_dda}{{3.9}{12}{MMD-based domain adaptation networks}{equation.46}{}}
\newlabel{eq_hD2_dda@cref}{{[equation][9][3]3.9}{[1][12][]12}}
\newlabel{eq_hD2_dda}{{3.10}{12}{MMD-based domain adaptation networks}{equation.47}{}}
\newlabel{eq_hD2_dda@cref}{{[equation][10][3]3.10}{[1][12][]12}}
\newlabel{eq_obj_learning_mmd}{{3.11}{12}{MMD-based domain adaptation networks}{equation.48}{}}
\newlabel{eq_obj_learning_mmd@cref}{{[equation][11][3]3.11}{[1][12][]12}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.3}{}}{13}{theorem.49}\protected@file@percent }
\newlabel{assum_Lk_Leta}{{3.3}{13}{MMD-based domain adaptation networks}{theorem.49}{}}
\newlabel{assum_Lk_Leta@cref}{{[assumption][3][3]3.3}{[1][13][]13}}
\newlabel{eq_assum_kernel_lip_cont}{{3.12}{13}{MMD-based domain adaptation networks}{equation.50}{}}
\newlabel{eq_assum_kernel_lip_cont@cref}{{[equation][12][3]3.12}{[1][13][]13}}
\newlabel{eq_Lipcont_act}{{3.13}{13}{MMD-based domain adaptation networks}{equation.51}{}}
\newlabel{eq_Lipcont_act@cref}{{[equation][13][3]3.13}{[1][13][]13}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.4}{}}{13}{theorem.52}\protected@file@percent }
\newlabel{assum_bnd_act_val_op}{{3.4}{13}{MMD-based domain adaptation networks}{theorem.52}{}}
\newlabel{assum_bnd_act_val_op@cref}{{[assumption][4][3]3.4}{[1][13][]13}}
\newlabel{eq_bnd_act_value}{{3.14}{13}{MMD-based domain adaptation networks}{equation.53}{}}
\newlabel{eq_bnd_act_value@cref}{{[equation][14][3]3.14}{[1][13][]13}}
\newlabel{eq_bnd_act_op}{{3.15}{13}{MMD-based domain adaptation networks}{equation.54}{}}
\newlabel{eq_bnd_act_op@cref}{{[equation][15][3]3.15}{[1][13][]13}}
\@writefile{thm}{\contentsline {corollary}{{Corollary}{3.5}{}}{13}{theorem.55}\protected@file@percent }
\newlabel{cor_covnum_rate}{{3.5}{13}{MMD-based domain adaptation networks}{theorem.55}{}}
\newlabel{cor_covnum_rate@cref}{{[corollary][5][3]3.5}{[1][13][]13}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{3.6}{}}{14}{theorem.56}\protected@file@percent }
\newlabel{thm_main_result_da_mmd}{{3.6}{14}{MMD-based domain adaptation networks}{theorem.56}{}}
\newlabel{thm_main_result_da_mmd@cref}{{[theorem][6][3]3.6}{[1][14][]14}}
\newlabel{eq_accuracy_thm4}{{3.16}{14}{MMD-based domain adaptation networks}{equation.57}{}}
\newlabel{eq_accuracy_thm4@cref}{{[equation][16][3]3.16}{[1][14][]14}}
\citation{GaninUAGLLML16}
\citation{TzengHSD17}
\citation{LongC0J18}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of adversarial domain adaptation networks}}{15}{figure.61}\protected@file@percent }
\newlabel{fig_illus_ddan_network}{{3}{15}{Illustration of adversarial domain adaptation networks}{figure.61}{}}
\newlabel{fig_illus_ddan_network@cref}{{[figure][3][]3}{[1][15][]15}}
\newlabel{ssec_adv_da_net}{{3.2}{15}{Adversarial domain adaptation networks}{subsection.60}{}}
\newlabel{ssec_adv_da_net@cref}{{[subsection][2][3]3.2}{[1][15][]15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adversarial domain adaptation networks}{15}{figure.61}\protected@file@percent }
\newlabel{eq_log_penalty_domainloss}{{3.18}{15}{Adversarial domain adaptation networks}{equation.63}{}}
\newlabel{eq_log_penalty_domainloss@cref}{{[equation][18][3]3.18}{[1][15][]15}}
\newlabel{eq_ddan_obj_func}{{3.19}{15}{Adversarial domain adaptation networks}{equation.64}{}}
\newlabel{eq_ddan_obj_func@cref}{{[equation][19][3]3.19}{[1][15][]15}}
\citation{SinghalWRK23}
\citation{TzengHSD17}
\citation{GaninUAGLLML16}
\citation{TzengHSD17}
\newlabel{eq_Fs_defn}{{3.20}{16}{Adversarial domain adaptation networks}{equation.65}{}}
\newlabel{eq_Fs_defn@cref}{{[equation][20][3]3.20}{[1][16][]16}}
\newlabel{eq_Dspace_defn}{{3.21}{16}{Adversarial domain adaptation networks}{equation.68}{}}
\newlabel{eq_Dspace_defn@cref}{{[equation][21][3]3.21}{[1][16][]16}}
\citation{GaninUAGLLML16}
\citation{TzengHDS15}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.7}{}}{17}{theorem.69}\protected@file@percent }
\newlabel{assum_ddan_bdd}{{3.7}{17}{Adversarial domain adaptation networks}{theorem.69}{}}
\newlabel{assum_ddan_bdd@cref}{{[assumption][7][3]3.7}{[1][17][]17}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.8}{}}{17}{theorem.70}\protected@file@percent }
\newlabel{assum_actddan_cont_Lip}{{3.8}{17}{Adversarial domain adaptation networks}{theorem.70}{}}
\newlabel{assum_actddan_cont_Lip@cref}{{[assumption][8][3]3.8}{[1][17][]17}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.9}{}}{17}{theorem.75}\protected@file@percent }
\newlabel{assum_bnd_act_val_op_ddan}{{3.9}{17}{Adversarial domain adaptation networks}{theorem.75}{}}
\newlabel{assum_bnd_act_val_op_ddan@cref}{{[assumption][9][3]3.9}{[1][17][]17}}
\@writefile{thm}{\contentsline {assumption}{{Assumption}{3.10}{}}{17}{theorem.76}\protected@file@percent }
\newlabel{assum_existence_LLsdan}{{3.10}{17}{Adversarial domain adaptation networks}{theorem.76}{}}
\newlabel{assum_existence_LLsdan@cref}{{[assumption][10][3]3.10}{[1][17][]17}}
\newlabel{fig:illus_domain_ddan_a}{{4a}{18}{Subfigure 4a}{subfigure.72}{}}
\newlabel{fig:illus_domain_ddan_a@cref}{{[subfigure][1][4]4a}{[1][17][]18}}
\newlabel{sub@fig:illus_domain_ddan_a}{{(a)}{a}{Subfigure 4a\relax }{subfigure.72}{}}
\newlabel{fig:illus_domain_ddan_b}{{4b}{18}{Subfigure 4b}{subfigure.73}{}}
\newlabel{fig:illus_domain_ddan_b@cref}{{[subfigure][2][4]4b}{[1][17][]18}}
\newlabel{sub@fig:illus_domain_ddan_b}{{(b)}{b}{Subfigure 4b\relax }{subfigure.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Illustration of \cref  {assum_existence_LLsdan}. Red and blue colors represent two different classes in the source and target domains. In (a), the two domains are poorly aligned by the mappings $\ensuremath  {f^s}$ and $\ensuremath  {f^t}$, therefore, the algorithm learns a domain discriminator $\ensuremath  {\Delta }$ that can separate the two domains well. The domain distance $\ensuremath  {\ensuremath  {D}_\ensuremath  {\Delta }}(\ensuremath  {f^s}, \ensuremath  {f^t})$ is then high, and consequently, there may exist hypotheses $\ensuremath  {h}$ yielding a small loss in one domain and a large loss in the other domain. In (b), the domains are well-aligned and the domain distance $\ensuremath  {\ensuremath  {D}_\ensuremath  {\Delta }}(\ensuremath  {f^s}, \ensuremath  {f^t})$ is small. The source and target losses are then similar for any hypothesis $\ensuremath  {h}$.}}{18}{figure.71}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Poor alignment}}}{18}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Proper alignment}}}{18}{subfigure.4.2}\protected@file@percent }
\newlabel{fig_illus_domain_ddan}{{4}{18}{Illustration of \cref {assum_existence_LLsdan}. Red and blue colors represent two different classes in the source and target domains. In (a), the two domains are poorly aligned by the mappings $\fs $ and $\ft $, therefore, the algorithm learns a domain discriminator $\ddan $ that can separate the two domains well. The domain distance $\Ddan (\fs , \ft )$ is then high, and consequently, there may exist hypotheses $\h $ yielding a small loss in one domain and a large loss in the other domain. In (b), the domains are well-aligned and the domain distance $\Ddan (\fs , \ft )$ is small. The source and target losses are then similar for any hypothesis $\h $}{figure.71}{}}
\newlabel{fig_illus_domain_ddan@cref}{{[figure][4][]4}{[1][17][]18}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{3.11}{}}{18}{theorem.78}\protected@file@percent }
\newlabel{thm_main_result_dann}{{3.11}{18}{Adversarial domain adaptation networks}{theorem.78}{}}
\newlabel{thm_main_result_dann@cref}{{[theorem][11][3]3.11}{[1][18][]18}}
\newlabel{eq_alpha_exrp_thm_ddan}{{3.22}{18}{Adversarial domain adaptation networks}{equation.79}{}}
\newlabel{eq_alpha_exrp_thm_ddan@cref}{{[equation][22][3]3.22}{[1][18][]18}}
\newlabel{eq_accuracy_thm_ddan}{{3.23}{19}{Adversarial domain adaptation networks}{equation.80}{}}
\newlabel{eq_accuracy_thm_ddan@cref}{{[equation][23][3]3.23}{[1][19][]19}}
\newlabel{eq_sample_complexity_thm_ddan}{{3.24}{19}{Adversarial domain adaptation networks}{equation.81}{}}
\newlabel{eq_sample_complexity_thm_ddan@cref}{{[equation][24][3]3.24}{[1][19][]19}}
\citation{MITCBCL}
\citation{FernandoHST13}
\citation{mnist}
\citation{mnistm}
\citation{LongCWJ15}
\citation{GaninUAGLLML16}
\newlabel{sec:exp_results}{{4}{20}{Experimental results}{section.84}{}}
\newlabel{sec:exp_results@cref}{{[section][4][]4}{[1][20][]20}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental results}{20}{section.84}\protected@file@percent }
\newlabel{ssec_exp_gen_da}{{4.1}{20}{General domain alignment methods}{subsection.85}{}}
\newlabel{ssec_exp_gen_da@cref}{{[subsection][1][4]4.1}{[1][20][]20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}General domain alignment methods}{20}{subsection.85}\protected@file@percent }
\newlabel{ssec_exp_dan}{{4.2}{20}{Domain-adaptive neural networks}{subsection.88}{}}
\newlabel{ssec_exp_dan@cref}{{[subsection][2][4]4.2}{[1][20][]20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Domain-adaptive neural networks}{20}{subsection.88}\protected@file@percent }
\newlabel{ssec_exp_mmd_dan}{{4.2.1}{20}{MMD-based domain adaptation networks}{subsubsection.90}{}}
\newlabel{ssec_exp_mmd_dan@cref}{{[subsubsection][1][4,2]4.2.1}{[1][20][]20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}MMD-based domain adaptation networks}{20}{subsubsection.90}\protected@file@percent }
\newlabel{exp_adv_da}{{4.2.2}{20}{Adversarial domain adaptation networks}{subsubsection.92}{}}
\newlabel{exp_adv_da@cref}{{[subsubsection][2][4,2]4.2.2}{[1][20][]20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Adversarial domain adaptation networks}{20}{subsubsection.92}\protected@file@percent }
\newlabel{fig:toy_error_Mt}{{5a}{21}{Subfigure 5a}{subfigure.96}{}}
\newlabel{fig:toy_error_Mt@cref}{{[subfigure][1][5]5a}{[1][20][]21}}
\newlabel{sub@fig:toy_error_Mt}{{(a)}{a}{Subfigure 5a\relax }{subfigure.96}{}}
\newlabel{fig:toy_error_tau}{{5b}{21}{Subfigure 5b}{subfigure.97}{}}
\newlabel{fig:toy_error_tau@cref}{{[subfigure][2][5]5b}{[1][20][]21}}
\newlabel{sub@fig:toy_error_tau}{{(b)}{b}{Subfigure 5b\relax }{subfigure.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Variation of the target error on synthetical data with (a) Number of labeled target samples, (b) Distribution distance after transformation. Solid lines indicate experimental data and dashed lines represent theoretical rates of variation.}}{21}{figure.95}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{21}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{21}{subfigure.5.2}\protected@file@percent }
\newlabel{fig:toy_error}{{5}{21}{Variation of the target error on synthetical data with (a) Number of labeled target samples, (b) Distribution distance after transformation. Solid lines indicate experimental data and dashed lines represent theoretical rates of variation}{figure.95}{}}
\newlabel{fig:toy_error@cref}{{[figure][5][]5}{[1][20][]21}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sample images from the MIT-CBCL face data set for four different subjects, rendered respectively under poses 1, 2, 5, and 9 for various illumination conditions. }}{21}{figure.99}\protected@file@percent }
\newlabel{fig:face_dataset}{{6}{21}{Sample images from the MIT-CBCL face data set for four different subjects, rendered respectively under poses 1, 2, 5, and 9 for various illumination conditions}{figure.99}{}}
\newlabel{fig:face_dataset@cref}{{[figure][6][]6}{[1][20][]21}}
\newlabel{fig:mit_error_Mt}{{7a}{21}{Subfigure 7a}{subfigure.102}{}}
\newlabel{fig:mit_error_Mt@cref}{{[subfigure][1][7]7a}{[1][20][]21}}
\newlabel{sub@fig:mit_error_Mt}{{(a)}{a}{Subfigure 7a\relax }{subfigure.102}{}}
\newlabel{fig:mit_error_Ms}{{7b}{21}{Subfigure 7b}{subfigure.103}{}}
\newlabel{fig:mit_error_Ms@cref}{{[subfigure][2][7]7b}{[1][20][]21}}
\newlabel{sub@fig:mit_error_Ms}{{(b)}{b}{Subfigure 7b\relax }{subfigure.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Variation of the target error on MIT-CBCL face data with (a) Number of labeled target samples, (b) Number of labeled source samples. Solid lines indicate experimental data and dashed lines represent theoretical rates of variation.}}{21}{figure.101}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{21}{subfigure.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{21}{subfigure.7.2}\protected@file@percent }
\newlabel{fig:mit_error}{{7}{21}{Variation of the target error on MIT-CBCL face data with (a) Number of labeled target samples, (b) Number of labeled source samples. Solid lines indicate experimental data and dashed lines represent theoretical rates of variation}{figure.101}{}}
\newlabel{fig:mit_error@cref}{{[figure][7][]7}{[1][20][]21}}
\citation{LongCWJ15}
\citation{LongCWJ15}
\newlabel{fig_mmd-layer-Ms-linefit}{{8a}{22}{Subfigure 8a}{subfigure.106}{}}
\newlabel{fig_mmd-layer-Ms-linefit@cref}{{[subfigure][1][8]8a}{[1][22][]22}}
\newlabel{sub@fig_mmd-layer-Ms-linefit}{{(a)}{a}{Subfigure 8a\relax }{subfigure.106}{}}
\newlabel{fig_mmd-layer-Ms-quadprog}{{8b}{22}{Subfigure 8b}{subfigure.107}{}}
\newlabel{fig_mmd-layer-Ms-quadprog@cref}{{[subfigure][2][8]8b}{[1][22][]22}}
\newlabel{sub@fig_mmd-layer-Ms-quadprog}{{(b)}{b}{Subfigure 8b\relax }{subfigure.107}{}}
\newlabel{fig_mmd-layer-Ns-linefit}{{8c}{22}{Subfigure 8c}{subfigure.108}{}}
\newlabel{fig_mmd-layer-Ns-linefit@cref}{{[subfigure][3][8]8c}{[1][22][]22}}
\newlabel{sub@fig_mmd-layer-Ns-linefit}{{(c)}{c}{Subfigure 8c\relax }{subfigure.108}{}}
\newlabel{fig_mmd-layer-Ns-quadprog}{{8d}{22}{Subfigure 8d}{subfigure.109}{}}
\newlabel{fig_mmd-layer-Ns-quadprog@cref}{{[subfigure][4][8]8d}{[1][22][]22}}
\newlabel{sub@fig_mmd-layer-Ns-quadprog}{{(d)}{d}{Subfigure 8d\relax }{subfigure.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sample complexity with respect to depth $\ensuremath  {L}$ for MMD-based networks \cite  {LongCWJ15}. Left panels show target accuracy variation with $\ensuremath  {L}$ at different sample sizes. Right panels show quadratic growth $\ensuremath  {M_s}, \ensuremath  {N_s}=O(\ensuremath  {L}^2)$.}}{22}{figure.105}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{22}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{22}{subfigure.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{22}{subfigure.8.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{22}{subfigure.8.4}\protected@file@percent }
\newlabel{fig_mmd_results_L}{{8}{22}{Sample complexity with respect to depth $\numL $ for MMD-based networks \cite {LongCWJ15}. Left panels show target accuracy variation with $\numL $ at different sample sizes. Right panels show quadratic growth $\Ms , \Ns =O(\numL ^2)$}{figure.105}{}}
\newlabel{fig_mmd_results_L@cref}{{[figure][8][]8}{[1][22][]22}}
\newlabel{fig_mmd-dim-Ms-linefit}{{9a}{22}{Subfigure 9a}{subfigure.112}{}}
\newlabel{fig_mmd-dim-Ms-linefit@cref}{{[subfigure][1][9]9a}{[1][22][]22}}
\newlabel{sub@fig_mmd-dim-Ms-linefit}{{(a)}{a}{Subfigure 9a\relax }{subfigure.112}{}}
\newlabel{fig_mmd-dim-Ms-quadprog}{{9b}{22}{Subfigure 9b}{subfigure.113}{}}
\newlabel{fig_mmd-dim-Ms-quadprog@cref}{{[subfigure][2][9]9b}{[1][22][]22}}
\newlabel{sub@fig_mmd-dim-Ms-quadprog}{{(b)}{b}{Subfigure 9b\relax }{subfigure.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Sample complexity with respect to width $\ensuremath  {{d}}$ for MMD-based networks. Quadratic growth $\ensuremath  {M_s}=O(\ensuremath  {{d}}^2)$ confirmed.}}{22}{figure.111}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{22}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{22}{subfigure.9.2}\protected@file@percent }
\newlabel{fig_mmd_results_d}{{9}{22}{Sample complexity with respect to width $\dcom $ for MMD-based networks. Quadratic growth $\Ms =O(\dcom ^2)$ confirmed}{figure.111}{}}
\newlabel{fig_mmd_results_d@cref}{{[figure][9][]9}{[1][22][]22}}
\newlabel{fig_adv-layer-Ms-linefit}{{10a}{23}{Subfigure 10a}{subfigure.116}{}}
\newlabel{fig_adv-layer-Ms-linefit@cref}{{[subfigure][1][10]10a}{[1][23][]23}}
\newlabel{sub@fig_adv-layer-Ms-linefit}{{(a)}{a}{Subfigure 10a\relax }{subfigure.116}{}}
\newlabel{fig_adv-layer-Ms-quadprog}{{10b}{23}{Subfigure 10b}{subfigure.117}{}}
\newlabel{fig_adv-layer-Ms-quadprog@cref}{{[subfigure][2][10]10b}{[1][23][]23}}
\newlabel{sub@fig_adv-layer-Ms-quadprog}{{(b)}{b}{Subfigure 10b\relax }{subfigure.117}{}}
\newlabel{fig_adv-layer-Ns-linefit}{{10c}{23}{Subfigure 10c}{subfigure.118}{}}
\newlabel{fig_adv-layer-Ns-linefit@cref}{{[subfigure][3][10]10c}{[1][23][]23}}
\newlabel{sub@fig_adv-layer-Ns-linefit}{{(c)}{c}{Subfigure 10c\relax }{subfigure.118}{}}
\newlabel{fig_adv-layer-Ns-quadprog}{{10d}{23}{Subfigure 10d}{subfigure.119}{}}
\newlabel{fig_adv-layer-Ns-quadprog@cref}{{[subfigure][4][10]10d}{[1][23][]23}}
\newlabel{sub@fig_adv-layer-Ns-quadprog}{{(d)}{d}{Subfigure 10d\relax }{subfigure.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sample complexity with respect to depth $\ensuremath  {L}$ for adversarial networks. Left: accuracy vs depth. Right: quadratic growth $\ensuremath  {M_s}, \ensuremath  {N_s}=O(\ensuremath  {L}^2)$.}}{23}{figure.115}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{23}{subfigure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{23}{subfigure.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{23}{subfigure.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{23}{subfigure.10.4}\protected@file@percent }
\newlabel{fig_adv_results_L}{{10}{23}{Sample complexity with respect to depth $\numL $ for adversarial networks. Left: accuracy vs depth. Right: quadratic growth $\Ms , \Ns =O(\numL ^2)$}{figure.115}{}}
\newlabel{fig_adv_results_L@cref}{{[figure][10][]10}{[1][23][]23}}
\newlabel{fig_mmd-optalpha_quadfit_Ms234}{{11a}{23}{Subfigure 11a}{subfigure.122}{}}
\newlabel{fig_mmd-optalpha_quadfit_Ms234@cref}{{[subfigure][1][11]11a}{[1][23][]23}}
\newlabel{sub@fig_mmd-optalpha_quadfit_Ms234}{{(a)}{a}{Subfigure 11a\relax }{subfigure.122}{}}
\newlabel{fig_mmd-optalpha-asqrtx_fit_den_Mss}{{11b}{23}{Subfigure 11b}{subfigure.123}{}}
\newlabel{fig_mmd-optalpha-asqrtx_fit_den_Mss@cref}{{[subfigure][2][11]11b}{[1][23][]23}}
\newlabel{sub@fig_mmd-optalpha-asqrtx_fit_den_Mss}{{(b)}{b}{Subfigure 11b\relax }{subfigure.123}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Optimal weight parameter for MMD-based networks. (a) Target accuracy variation with $\alpha $ shows non-monotonic behavior. (b) Optimal $\alpha _{opt}$ scales as $O(\sqrt  {\ensuremath  {M_t}})$.}}{23}{figure.121}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{23}{subfigure.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{23}{subfigure.11.2}\protected@file@percent }
\newlabel{fig_mmd_results_alpha}{{11}{23}{Optimal weight parameter for MMD-based networks. (a) Target accuracy variation with $\alpha $ shows non-monotonic behavior. (b) Optimal $\alpha _{opt}$ scales as $O(\sqrt {\Mt })$}{figure.121}{}}
\newlabel{fig_mmd_results_alpha@cref}{{[figure][11][]11}{[1][23][]23}}
\newlabel{fig_adv-dcm-Ms-linefit}{{12a}{24}{Subfigure 12a}{subfigure.126}{}}
\newlabel{fig_adv-dcm-Ms-linefit@cref}{{[subfigure][1][12]12a}{[1][24][]24}}
\newlabel{sub@fig_adv-dcm-Ms-linefit}{{(a)}{a}{Subfigure 12a\relax }{subfigure.126}{}}
\newlabel{fig_adv-dcm-Ms-quadprog}{{12b}{24}{Subfigure 12b}{subfigure.127}{}}
\newlabel{fig_adv-dcm-Ms-quadprog@cref}{{[subfigure][2][12]12b}{[1][24][]24}}
\newlabel{sub@fig_adv-dcm-Ms-quadprog}{{(b)}{b}{Subfigure 12b\relax }{subfigure.127}{}}
\newlabel{fig_adv-dcm-Ns-linefit}{{12c}{24}{Subfigure 12c}{subfigure.128}{}}
\newlabel{fig_adv-dcm-Ns-linefit@cref}{{[subfigure][3][12]12c}{[1][24][]24}}
\newlabel{sub@fig_adv-dcm-Ns-linefit}{{(c)}{c}{Subfigure 12c\relax }{subfigure.128}{}}
\newlabel{fig_adv-dcm-Ns-quadprog}{{12d}{24}{Subfigure 12d}{subfigure.129}{}}
\newlabel{fig_adv-dcm-Ns-quadprog@cref}{{[subfigure][4][12]12d}{[1][24][]24}}
\newlabel{sub@fig_adv-dcm-Ns-quadprog}{{(d)}{d}{Subfigure 12d\relax }{subfigure.129}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Sample complexity with respect to width $\ensuremath  {{d}}$ for adversarial networks. Left: accuracy vs width. Right: quadratic growth $\ensuremath  {M_s}, \ensuremath  {N_s}= O(\ensuremath  {{d}}^2)$.}}{24}{figure.125}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{24}{subfigure.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{24}{subfigure.12.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{24}{subfigure.12.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{24}{subfigure.12.4}\protected@file@percent }
\newlabel{fig_adv_results_d}{{12}{24}{Sample complexity with respect to width $\dcom $ for adversarial networks. Left: accuracy vs width. Right: quadratic growth $\Ms , \Ns = O(\dcom ^2)$}{figure.125}{}}
\newlabel{fig_adv_results_d@cref}{{[figure][12][]12}{[1][24][]24}}
\newlabel{fig_adv-optalpha_quadfit_Ms240}{{13a}{24}{Subfigure 13a}{subfigure.132}{}}
\newlabel{fig_adv-optalpha_quadfit_Ms240@cref}{{[subfigure][1][13]13a}{[1][24][]24}}
\newlabel{sub@fig_adv-optalpha_quadfit_Ms240}{{(a)}{a}{Subfigure 13a\relax }{subfigure.132}{}}
\newlabel{fig_adv-optalpha-asqrtx_fit_den_Mss.pdf}{{13b}{24}{Subfigure 13b}{subfigure.133}{}}
\newlabel{fig_adv-optalpha-asqrtx_fit_den_Mss.pdf@cref}{{[subfigure][2][13]13b}{[1][24][]24}}
\newlabel{sub@fig_adv-optalpha-asqrtx_fit_den_Mss.pdf}{{(b)}{b}{Subfigure 13b\relax }{subfigure.133}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Optimal weight for adversarial networks. (a) Accuracy vs $\alpha $. (b) $\alpha _{opt}$ scales as $O(\sqrt  {\ensuremath  {M_t}})$.}}{24}{figure.131}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{24}{subfigure.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{24}{subfigure.13.2}\protected@file@percent }
\newlabel{fig_adv_results_alpha}{{13}{24}{Optimal weight for adversarial networks. (a) Accuracy vs $\alpha $. (b) $\alpha _{opt}$ scales as $O(\sqrt {\Mt })$}{figure.131}{}}
\newlabel{fig_adv_results_alpha@cref}{{[figure][13][]13}{[1][24][]24}}
\citation{BenDavidBCP06}
\citation{BenDavidBCKPV10}
\citation{MansourMR09}
\citation{NeyshaburTS15}
\citation{WeiM19}
\newlabel{sec:conclusion}{{5}{25}{Conclusion}{section.135}{}}
\newlabel{sec:conclusion@cref}{{[section][5][]5}{[1][25][]25}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{25}{section.135}\protected@file@percent }
\bibstyle{siamplain}
\bibdata{refs}
\bibcite{AnthonyB02}{1}
\bibcite{Azizzadenesheli19}{2}
\bibcite{BaktashmotlaghHLS13}{3}
\bibcite{BenDavidBCKPV10}{4}
\bibcite{BenDavidBCP06}{5}
\bibcite{BousmalisTSKE16}{6}
\bibcite{CourtyFTR17}{7}
\bibcite{CuckerS02}{8}
\bibcite{DamodaranKFTC18}{9}
\bibcite{DanielyG24}{10}
\bibcite{DaumeIII07}{11}
\bibcite{DaumeKS10}{12}
\bibcite{DhouibRL20}{13}
\bibcite{DuanXT12}{14}
\bibcite{DunfordS88}{15}
\bibcite{HamriBF25}{16}
\bibcite{FangLLZ23}{17}
\bibcite{FernandoHST13}{18}
\bibcite{TomerWH16}{19}
\bibcite{mnistm}{20}
\bibcite{GaninUAGLLML16}{21}
\bibcite{GhifaryKZ14}{22}
\bibcite{GhifaryKZBL16}{23}
\bibcite{GrettonBRSS12}{24}
\bibcite{HuangSGBS06}{25}
\bibcite{JiaoLLY24}{26}
\bibcite{KouwL21}{27}
\bibcite{mnist}{28}
\bibcite{LongCWJ15}{29}
\bibcite{LongC0J18}{30}
\bibcite{MansourMR09}{31}
\bibcite{MITCBCL}{32}
\bibcite{McNamaraB17}{33}
\bibcite{NeyshaburTS15}{34}
\bibcite{PanTKY11}{35}
\bibcite{RedkoMHS20}{36}
\bibcite{SinghalWRK23}{37}
\bibcite{SunS16}{38}
\bibcite{SunCPY11}{39}
\bibcite{Combes0WG20}{40}
\bibcite{TangJ20}{41}
\bibcite{TzengHDS15}{42}
\bibcite{TzengHSD17}{43}
\bibcite{TzengHZSD14}{44}
\bibcite{VardiSS22}{45}
\bibcite{Vural18}{46}
\bibcite{WangD18}{47}
\bibcite{WangS15}{48}
\bibcite{WangM24}{49}
\bibcite{WangYXWZW23}{50}
\bibcite{WeiM19}{51}
\bibcite{DXiaLZSL25}{52}
\bibcite{YangZLLLC25}{53}
\bibcite{YaoPNLM15}{54}
\bibcite{Yurinski76}{55}
\bibcite{ZengSRGFZ25}{56}
\bibcite{ZhangLLJ19}{57}
\bibcite{ZhouTPT19}{58}
\bibcite{ZonooziS23}{59}
\bibcite{ZonooziSD25}{60}
\gdef \@abspage@last{28}
